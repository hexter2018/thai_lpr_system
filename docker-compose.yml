version: '3.8'

services:
  # ==================== Infrastructure ====================
  postgres:
    image: postgres:16
    environment:
      TZ: Asia/Bangkok
      POSTGRES_USER: lpr
      POSTGRES_PASSWORD: lpr2024
      POSTGRES_DB: lpr_v2
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lpr -d lpr_v2"]
      interval: 3s
      timeout: 3s
      retries: 30
    networks:
      - lpr-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 4gb --maxmemory-policy allkeys-lru
    environment:
      TZ: Asia/Bangkok
    ports:
      - "6379:6379"
    volumes:
      - redisdata:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 3s
      timeout: 3s
      retries: 30
    networks:
      - lpr-network

  # ==================== Backend API ====================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      TZ: Asia/Bangkok
      DATABASE_URL: postgresql+asyncpg://lpr:lpr2024@postgres:5432/lpr_v2
      REDIS_URL: redis://redis:6379/0
      STORAGE_DIR: /storage
      MODELS_DIR: /models
      CORS_ORIGINS: http://localhost:3000,http://10.32.70.136,http://10.32.70.136:3000
    volumes:
      - ./storage:/storage
      - ./models:/models
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - lpr-network
    restart: unless-stopped

  # ==================== AI Worker (TensorRT + ByteTrack) ====================
  worker-gpu:
    build:
      context: ./worker
      dockerfile: Dockerfile.gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    environment:
      TZ: Asia/Bangkok
      CUDA_VISIBLE_DEVICES: "0"
      
      # Database & Redis
      DATABASE_URL: postgresql+asyncpg://lpr:lpr2024@postgres:5432/lpr_v2
      REDIS_URL: redis://redis:6379/0
      STORAGE_DIR: /storage
      MODELS_DIR: /models
      
      # TensorRT Settings
      TRT_WORKSPACE: "6144"
      TRT_FP16: "1"
      
      # Vehicle Detection Model
      VEHICLE_MODEL_PATH: /models/vehicles.engine
      VEHICLE_CONF_THRESHOLD: "0.40"
      VEHICLE_IOU_THRESHOLD: "0.50"
      
      # Plate Detection Model
      PLATE_MODEL_PATH: /models/best.engine
      PLATE_CONF_THRESHOLD: "0.35"
      PLATE_IOU_THRESHOLD: "0.45"
      
      # ByteTrack Configuration
      TRACK_THRESH: "0.45"
      TRACK_BUFFER: "30"
      MATCH_THRESH: "0.80"
      
      # Zone Trigger Configuration
      ZONE_TRIGGER_ENABLED: "true"
      ZONE_TRIGGER_ONCE_PER_TRACK: "true"
      ZONE_MIN_FRAMES_IN_ZONE: "3"
      
      # OCR Configuration
      OCR_LANGUAGE: "th,en"
      OCR_GPU: "true"
      OCR_PROVINCE_MATCHING_ENABLED: "true"
      OCR_PROVINCE_MIN_SCORE: "70.0"
      
      # Active Learning
      ACTIVE_LEARNING_ENABLED: "true"
      MLPR_EXPORT_DIR: /storage/retrain_easyocr
      
      # Worker Settings
      CELERY_WORKER_CONCURRENCY: "4"
      CELERY_WORKER_PREFETCH: "8"
      
    volumes:
      - ./storage:/storage
      - ./models:/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - lpr-network
    restart: unless-stopped

  # ==================== RTSP Stream Manager ====================
  stream-manager:
    build:
      context: ./backend
      dockerfile: Dockerfile.stream
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu, video]
    environment:
      TZ: Asia/Bangkok
      CUDA_VISIBLE_DEVICES: "0"
      DATABASE_URL: postgresql+asyncpg://lpr:lpr2024@postgres:5432/lpr_v2
      REDIS_URL: redis://redis:6379/0
      STORAGE_DIR: /storage
      MODELS_DIR: /models
      
      # Stream Settings
      RTSP_RECONNECT_DELAY: "5"
      RTSP_BUFFER_SIZE: "2"
      STREAM_FPS_TARGET: "10"
      
      # MJPEG Server for Web Preview
      MJPEG_SERVER_ENABLED: "true"
      MJPEG_SERVER_PORT: "8090"
      MJPEG_QUALITY: "85"
      
    volumes:
      - ./storage:/storage
      - ./models:/models
    ports:
      - "8090:8090"
    depends_on:
      - backend
      - worker-gpu
    networks:
      - lpr-network
    restart: unless-stopped

  # ==================== Monitoring ====================
  flower:
    image: mher/flower:2.0
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - "5555:5555"
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
    depends_on:
      - redis
    networks:
      - lpr-network

  # ==================== Frontend ====================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      TZ: Asia/Bangkok
      VITE_API_BASE: http://10.32.70.136:8000
      VITE_MJPEG_BASE: http://10.32.70.136:8090
      VITE_STREAM_BASE: http://10.32.70.136:8090
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - lpr-network
    restart: unless-stopped

volumes:
  pgdata:
  redisdata:

networks:
  lpr-network:
    driver: bridge

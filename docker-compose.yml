version: '3.8'

services:
  # ==================== Infrastructure ====================
  postgres:
    image: postgres:16
    environment:
      TZ: Asia/Bangkok
      POSTGRES_USER: lpr
      POSTGRES_PASSWORD: lpr2024
      POSTGRES_DB: lpr_v2
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lpr -d lpr_v2"]
      interval: 3s
      timeout: 3s
      retries: 30
    networks:
      - lpr-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 4gb --maxmemory-policy allkeys-lru
    environment:
      TZ: Asia/Bangkok
    ports:
      - "6379:6379"
    volumes:
      - redisdata:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 3s
      timeout: 3s
      retries: 30
    networks:
      - lpr-network

  # ==================== Backend API ====================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      TZ: Asia/Bangkok
      DATABASE_URL: postgresql+asyncpg://lpr:lpr2024@postgres:5432/lpr_v2
      REDIS_URL: redis://redis:6379/0
      STORAGE_DIR: /storage
      MODELS_DIR: /models
      CORS_ORIGINS: http://localhost:3000,http://10.32.70.136,http://10.32.70.136:3000
    volumes:
      - ./storage:/storage
      - ./models:/models
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - lpr-network
    restart: unless-stopped

  # ==================== AI Worker (TensorRT + ByteTrack) ====================
  worker-gpu:
    build:
      context: ./worker
      dockerfile: Dockerfile.gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    environment:
      TZ: Asia/Bangkok
      CUDA_VISIBLE_DEVICES: "0"
      
      # Database & Redis
      DATABASE_URL: postgresql+asyncpg://lpr:lpr2024@postgres:5432/lpr_v2
      REDIS_URL: redis://redis:6379/0
      STORAGE_DIR: /storage
      MODELS_DIR: /models
      
      # ===== เพิ่มส่วนนี้ =====
      # TensorRT Settings
      USE_TRT_DETECTOR: "true"
      MODEL_PATH: /models/.model_path
      TRT_WORKSPACE: "6144"
      TRT_FP16: "1"
      TRT_INPUT_W: "640"
      TRT_INPUT_H: "640"
      TRT_CONF_THRES: "0.35"
      TRT_IOU_THRES: "0.45"
      TRT_CLASS_ID: "0"
      
      # Plate Detection Model
      PLATE_MODEL_PATH: /models/.model_path
      PLATE_CONF_THRESHOLD: "0.35"
      PLATE_IOU_THRESHOLD: "0.45"
      
      # OCR Configuration
      OCR_LANGUAGE: "th,en"
      OCR_GPU: "true"
      OCR_VARIANT_LIMIT: "16"
      OCR_TOP_K: "3"
      OCR_CONSENSUS_MIN: "0.55"
      OCR_MARGIN_MIN: "0.16"
      
      # Crop Validation
      CROP_VALIDATOR_ENABLED: "true"
      CROP_MIN_WIDTH: "40"
      CROP_MIN_HEIGHT: "15"
      CROP_MIN_ASPECT_RATIO: "1.5"
      CROP_MAX_ASPECT_RATIO: "7.0"
      CROP_MIN_CONTRAST: "20.0"
      CROP_MIN_EDGE_DENSITY: "0.03"
      
      # Plate Deduplication
      PLATE_DEDUP_ENABLED: "true"
      PLATE_DEDUP_COOLDOWN_SEC: "60"
      PLATE_DEDUP_MIN_CONFIDENCE: "0.30"
      PLATE_DEDUP_CAMERA_SCOPE: "true"
      
      # Master Plate Threshold
      MASTER_CONF_THRESHOLD: "0.95"
      
      # Worker Settings
      CELERY_WORKER_CONCURRENCY: "4"
      CELERY_WORKER_PREFETCH: "8"
    volumes:
      - ./storage:/storage
      - ./models:/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - lpr-network
    restart: unless-stopped

  # ==================== RTSP Stream Manager ====================
  stream-manager:
    build:
      context: .
      dockerfile: backend/Dockerfile.stream
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu, video]
    environment:
      TZ: Asia/Bangkok
      CUDA_VISIBLE_DEVICES: "0"
      DATABASE_URL: postgresql+asyncpg://lpr:lpr2024@postgres:5432/lpr_v2
      REDIS_URL: redis://redis:6379/0
      STORAGE_DIR: /storage
      MODELS_DIR: /models
      
            # ===== เพิ่มส่วนนี้ =====
      # Counting Line Configuration (JSON format)
      COUNT_LINE: '[[100, 400], [900, 400]]'
      
      # TensorRT Vehicle Detector
      USE_TRT_VEHICLE_DETECTOR: "true"
      VEHICLE_MODEL_PATH: /models/.vehicle_model_path
      
      # Tracking Parameters
      TRACK_THRESH: "0.45"
      TRACK_BUFFER: "30"
      MATCH_THRESH: "0.80"
      TRAJECTORY_MAXLEN: "30"
      FALLBACK_TRACK_IOU_THRESH: "0.30"
      VEHICLE_MIN_BLOB_AREA: "5000"

      # Stream Settings
      RTSP_RECONNECT_DELAY: "5"
      RTSP_BUFFER_SIZE: "2"
      STREAM_FPS_TARGET: "10"
      
      # MJPEG Server for Web Preview
      MJPEG_SERVER_ENABLED: "true"
      MJPEG_SERVER_PORT: "8090"
      MJPEG_QUALITY: "85"
      
    volumes:
      - ./storage:/storage
      - ./models:/models
    ports:
      - "8090:8090"
    depends_on:
      - backend
      - worker-gpu
    networks:
      - lpr-network
    restart: unless-stopped

  # ==================== Monitoring ====================
  flower:
    image: mher/flower:2.0
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - "5555:5555"
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
    depends_on:
      - redis
    networks:
      - lpr-network

  # ==================== Frontend ====================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_API_BASE: /api
        VITE_MJPEG_BASE: /stream
        VITE_STREAM_BASE: /stream
    environment:
      TZ: Asia/Bangkok
    ports:
      - "3000:3000"
    depends_on:
      - backend
      - stream-manager
    networks:
      - lpr-network
    restart: unless-stopped

volumes:
  pgdata:
  redisdata:

networks:
  lpr-network:
    driver: bridge
